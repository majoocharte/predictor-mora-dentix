{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zN-GEndvSdh7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from statsmodels.multivariate.manova import MANOVA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.cluster import KMeans\n",
        "from xgboost import plot_importance\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from statsmodels.multivariate.manova import MANOVA\n",
        "import seaborn as sns\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, make_scorer\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "random.seed(42)\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_excel('BD_numericas.xlsx')"
      ],
      "metadata": {
        "id": "71YmJVP8SnhE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = data"
      ],
      "metadata": {
        "id": "q0CgmotjUc5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "RQWLM7vzUvhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['MORA'] = (df['DIAS DE MORA'] >= 30).astype(int)\n"
      ],
      "metadata": {
        "id": "R_Z6drs8T3H2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = df.columns.str.replace(\" \", \"_\")"
      ],
      "metadata": {
        "id": "GTzSGqcBXb7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "variables_manova = [\n",
        "    'SCORE',\n",
        "    'MONTO_DESEMBOLSO',\n",
        "    'EDAD',\n",
        "    'NIVEL_ESTUDIOS',\n",
        "    'INGRESOS_FIJOS',\n",
        "    'GASTOS_DE_SOSTENIMIENTO',\n",
        "    'ACTIVOS',\n",
        "    'TIEMPO_ACTIVIDAD',\n",
        "    'TIEMPO_EN_RESIDENCIA',\n",
        "    'CODIGO_CIIU',\n",
        "    'ESTADOCIVIL',\n",
        "    'ESTRATO'\n",
        "]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "981Cs0cWWXpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['TOTAL_INGRESOS']"
      ],
      "metadata": {
        "id": "fo8uc7NZWmpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "df_scaled = df.copy()\n",
        "\n",
        "df_scaled[variables_manova] = scaler.fit_transform(df[variables_manova])\n",
        "\n",
        "maov_scaled = MANOVA.from_formula(\n",
        "    \"SCORE + INGRESOS_FIJOS + TOTAL_INGRESOS + TIEMPO_ACTIVIDAD + TIEMPO_EN_RESIDENCIA + EDAD + NIVEL_ESTUDIOS + ACTIVOS + GASTOS_DE_SOSTENIMIENTO + CODIGO_CIIU + ESTADOCIVIL + ESTRATO ~ MORA\",\n",
        "    data=df_scaled\n",
        ")\n",
        "\n",
        "print(maov_scaled.mv_test())"
      ],
      "metadata": {
        "id": "ZoCcX4axWZY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LDA"
      ],
      "metadata": {
        "id": "u943BtftYpja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Imputación de NA\n",
        "imp = SimpleImputer(strategy=\"median\")\n",
        "X = imp.fit_transform(df[variables_manova])\n",
        "y = df[\"MORA\"]\n",
        "\n",
        "# Balanceo con SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_bal, y_bal = smote.fit_resample(X, y)\n",
        "\n",
        "#Entrenamiento del modelo\n",
        "lda = LinearDiscriminantAnalysis()\n",
        "lda.fit(X_bal, y_bal)\n",
        "\n",
        "y_pred = lda.predict(X)\n",
        "\n",
        "print(\"\\n Accuracy LDA:\", accuracy_score(y, y_pred))\n",
        "print(\"\\n Classification Report:\\n\", classification_report(y, y_pred))\n",
        "print(\"\\n Matriz de Confusión:\\n\", confusion_matrix(y, y_pred))\n"
      ],
      "metadata": {
        "id": "JPfWfLc1YoCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importancia de las variables"
      ],
      "metadata": {
        "id": "az0P5ovaY_lk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coef = pd.DataFrame({\n",
        "    \"Variable\": variables_manova,\n",
        "    \"Peso_LDA\": lda.coef_[0]\n",
        "}).sort_values(by=\"Peso_LDA\", ascending=False)\n",
        "\n",
        "print(\"\\n Ranking de importancia LDA:\\n\")\n",
        "print(coef)"
      ],
      "metadata": {
        "id": "_dHKUQdtZAzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_plot = pd.DataFrame({\"LDA1\": lda.transform(X)[:,0], \"MORA\": y})\n",
        "\n",
        "sns.kdeplot(data=df_plot, x=\"LDA1\", hue=\"MORA\", fill=True, alpha=0.4)\n",
        "plt.axvline(0, linestyle=\"--\", color=\"black\")\n",
        "plt.title(\"Separación entre morosos y no morosos – LDA1\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AEOfmoZUZqzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Umbrales para LDA"
      ],
      "metadata": {
        "id": "C6_rhF9TfcQx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_proba_lda = lda.predict_proba(X)[:,1]\n",
        "\n",
        "# Probando umbrales de 0.1 a 0.9\n",
        "thresholds = [i/100 for i in range(5,95,5)]\n",
        "resultados = []\n",
        "\n",
        "for t in thresholds:\n",
        "    y_pred_t = (y_proba_lda >= t).astype(int)\n",
        "    resultados.append([\n",
        "        t,\n",
        "        precision_score(y, y_pred_t),\n",
        "        recall_score(y, y_pred_t),\n",
        "        f1_score(y, y_pred_t)\n",
        "    ])\n",
        "\n",
        "import pandas as pd\n",
        "tabla_lda = pd.DataFrame(resultados, columns=[\"threshold\",\"precision\",\"recall\",\"f1\"])\n",
        "print(tabla_lda)"
      ],
      "metadata": {
        "id": "c9BWmLJIfahz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Probabilidades LDA ya entrenado\n",
        "y_proba_lda = lda.predict_proba(X)[:,1]\n",
        "\n",
        "# Cambiando treshold\n",
        "threshold = 0.45\n",
        "y_pred_045 = (y_proba_lda >= threshold).astype(int)\n",
        "\n",
        "print(f\"\\n Resultados con Threshold = {threshold}\")\n",
        "print(\"Accuracy:\", accuracy_score(y, y_pred_045))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y, y_pred_045))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y, y_pred_045))"
      ],
      "metadata": {
        "id": "mo15gpyNgIPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coef = pd.DataFrame({\n",
        "    \"Variable\": variables_manova,\n",
        "    \"Peso_LDA\": lda.coef_[0]\n",
        "})\n",
        "\n",
        "coef[\"|Peso|\"] = coef[\"Peso_LDA\"].abs()\n",
        "coef.sort_values(by=\"|Peso|\", ascending=False, inplace=True)\n",
        "\n",
        "print(\"\\n Ranking de variables LDA:\\n\")\n",
        "print(coef.drop(columns=\"|Peso|\"))"
      ],
      "metadata": {
        "id": "KszWGjEe-hVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBOOST"
      ],
      "metadata": {
        "id": "K3vTneFAipDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "imp = SimpleImputer(strategy=\"median\")\n",
        "X_train = imp.fit_transform(X_train)\n",
        "X_test  = imp.transform(X_test)\n",
        "\n",
        "model = XGBClassifier(\n",
        "    learning_rate=0.05,\n",
        "    max_depth=5,\n",
        "    n_estimators=300,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    eval_metric=\"logloss\"\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"AUC:\", roc_auc_score(y_test, model.predict_proba(X_test)[:,1]))"
      ],
      "metadata": {
        "id": "Q79jsNJEinUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sm = SMOTE(random_state=42)\n",
        "X_train_bal, y_train_bal = sm.fit_resample(X_train, y_train)\n",
        "model.fit(X_train_bal, y_train_bal)"
      ],
      "metadata": {
        "id": "xjCA_HbEkVuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_bal = model.predict(X_test)\n",
        "y_proba_bal = model.predict_proba(X_test)[:,1]\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "\n",
        "print(\"\\n Resultados XGBoost + SMOTE\")\n",
        "print(classification_report(y_test, y_pred_bal))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_bal))\n",
        "print(\"AUC:\", roc_auc_score(y_test, y_proba_bal))"
      ],
      "metadata": {
        "id": "da9nbyuPlLRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seleccion del umbral"
      ],
      "metadata": {
        "id": "NVahhK7olqlw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluar_threshold_smote(thresholds, y_test, y_prob):\n",
        "    resultados = []\n",
        "    for t in thresholds:\n",
        "        y_pred = (y_prob >= t).astype(int)\n",
        "        resultados.append([\n",
        "            t,\n",
        "            precision_score(y_test, y_pred),\n",
        "            recall_score(y_test, y_pred),\n",
        "            f1_score(y_test, y_pred)\n",
        "        ])\n",
        "    return pd.DataFrame(resultados, columns=[\"threshold\",\"precision\",\"recall\",\"f1\"])\n",
        "\n",
        "\n",
        "thresholds = np.arange(0.10, 0.91, 0.05)\n",
        "tabla_t = evaluar_threshold_smote(thresholds, y_test, y_proba_bal)\n",
        "print(tabla_t)"
      ],
      "metadata": {
        "id": "gOckg5Nelrq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 0.15\n",
        "y_pred_thr = (y_proba_bal >= threshold).astype(int)\n",
        "\n",
        "print(f\"\\n* Resultados con threshold = {threshold} *\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_thr))\n",
        "print(\"\\nReporte de Clasificación:\")\n",
        "print(classification_report(y_test, y_pred_thr))\n",
        "print(\"\\nMatriz de Confusión:\")\n",
        "print(confusion_matrix(y_test, y_pred_thr))"
      ],
      "metadata": {
        "id": "AUy9D9n8l_9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auc = roc_auc_score(y_test, y_proba_bal)\n",
        "print(f\"\\nAUC ROC del modelo: {auc:.4f}\")"
      ],
      "metadata": {
        "id": "WvZkxO8Yandp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kmeans"
      ],
      "metadata": {
        "id": "vWH-J0cms1Kb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score"
      ],
      "metadata": {
        "id": "MDyDoGRTs9gj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vars_segmento = [\n",
        "    \"SCORE\",\"CUOTAMENSUAL\",\"INGRESOS_FIJOS\",\n",
        "    \"TIEMPO_ACTIVIDAD\",\"TIEMPO_EN_RESIDENCIA\",\n",
        "    \"EDAD\",\"TASA\",\"PLAZO\"\n",
        "]\n",
        "\n",
        "X_seg = df[vars_segmento]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_seg)\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "for k in range(2,7):\n",
        "    km = KMeans(n_clusters=k, random_state=42)\n",
        "    labels = km.fit_predict(X_pca)\n",
        "    print(f\"k={k} → Silhouette={silhouette_score(X_pca, labels):.3f}\")\n"
      ],
      "metadata": {
        "id": "nuL2xjEDtA-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Elegimos el mayor sil\n",
        "k_optimo = 3\n",
        "kmeans = KMeans(n_clusters=k_optimo, random_state=42)\n",
        "df[\"cluster_final\"] = kmeans.fit_predict(X_pca)"
      ],
      "metadata": {
        "id": "bxmiRPNGtqby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_summary = df.groupby(\"cluster_final\")[vars_segmento].mean()\n",
        "print(cluster_summary)"
      ],
      "metadata": {
        "id": "pwBk0FCEuJoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tamaño de clusters"
      ],
      "metadata": {
        "id": "r98xMv3SuOBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"cluster_final\"].value_counts()"
      ],
      "metadata": {
        "id": "a_zxI0xEuPV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby(\"cluster_final\")[vars_segmento].median()"
      ],
      "metadata": {
        "id": "q4Q49KIHuSbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[vars_segmento+[\"cluster_final\"]].groupby(\"cluster_final\").describe()"
      ],
      "metadata": {
        "id": "ay9puxhZuVsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(7,6))\n",
        "plt.scatter(X_pca[:,0], X_pca[:,1], c=df[\"cluster_final\"], cmap=\"viridis\", alpha=0.6)\n",
        "plt.title(\"Clusters usando PCA + KMeans\")\n",
        "plt.xlabel(\"PC1\")\n",
        "plt.ylabel(\"PC2\")\n",
        "plt.colorbar(label=\"Cluster\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "r8z0IXOfufK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loadings = pd.DataFrame(\n",
        "    pca.components_.T,\n",
        "    columns=['PC1','PC2'],\n",
        "    index=vars_segmento\n",
        ")\n",
        "loadings"
      ],
      "metadata": {
        "id": "GLa9Ivb0KaCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,6))\n",
        "scatter = plt.scatter(X_pca[:,0], X_pca[:,1], c=df[\"cluster_final\"], cmap=\"viridis\", alpha=0.6)\n",
        "plt.colorbar(scatter, label=\"Cluster\")\n",
        "plt.xlabel(\"PC1\")\n",
        "plt.ylabel(\"PC2\")\n",
        "plt.title(\"Clusters con vectores PCA\")\n",
        "\n",
        "for i, var in enumerate(loadings.index):\n",
        "    plt.arrow(0,0, loadings.PC1[i]*3, loadings.PC2[i]*3, color='red', width=0.01)\n",
        "    plt.text(loadings.PC1[i]*3.2, loadings.PC2[i]*3.2, var, color='red')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "l7DDIaxXKn8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Robustez"
      ],
      "metadata": {
        "id": "P6wD_vLEbkFx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "df_test = df.loc[y_test.index].copy()\n",
        "\n",
        "subgroups = {\n",
        "    \"Género\": \"GÉNERO\",\n",
        "    \"Estrato\": \"ESTRATO\",\n",
        "    \"Nivel de estudios\": \"NIVEL_ESTUDIOS\",\n",
        "}\n",
        "\n",
        "for nombre, col in subgroups.items():\n",
        "    print(f\"\\n== Robustez por {nombre} ({col}) ==\")\n",
        "\n",
        "    for valor in sorted(df_test[col].dropna().unique()):\n",
        "        mask = df_test[col] == valor\n",
        "\n",
        "        if mask.sum() < 100:\n",
        "            continue\n",
        "\n",
        "        print(f\"\\nSubgrupo: {valor}  (n = {mask.sum()})\")\n",
        "        print(classification_report(y_test[mask], y_pred_thr[mask], digits=2))"
      ],
      "metadata": {
        "id": "BUc2CEQnbga5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
